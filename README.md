# ğŸ¤– IA UNEB - Perguntas e Respostas com Interface PyQt6

Este Ã© um projeto interativo de interface grÃ¡fica desenvolvido em **Python com PyQt6**, que permite ao usuÃ¡rio fazer **perguntas para uma IA** baseada em LLM local (via Ollama) com contexto vindo de um **banco de dados de lojas**. O sistema otimiza o tempo de resposta utilizando cache em um banco PostgreSQL.

---

## ğŸ§  Funcionalidades

- âœ… Interface moderna em PyQt6
- ğŸ§¾ Consulta a IA com contexto das lojas cadastradas
- ğŸ’¾ Banco de dados PostgreSQL com persistÃªncia de:
  - Perguntas e respostas
  - AvaliaÃ§Ã£o do usuÃ¡rio sobre a resposta (correta/incorreta)
- âš¡ Cache inteligente:
  - Respostas jÃ¡ fornecidas pela IA sÃ£o reaproveitadas automaticamente
- ğŸ§‘â€ğŸ« CorreÃ§Ã£o manual:
  - Se a IA errar, o usuÃ¡rio pode digitar a resposta certa e salvÃ¡-la

---

## ğŸ–¥ï¸ Telas do sistema

| Tela de pergunta | Tela de resposta | CorreÃ§Ã£o manual |
|------------------|------------------|------------------|
| UsuÃ¡rio digita sua pergunta e envia para IA | A IA responde; usuÃ¡rio avalia se estÃ¡ correta | Se clicar "Errado", pode digitar a resposta correta |

---

## ğŸ§ª Como executar

1. **Clone o projeto:**

```bash
git clone https://github.com/seu-usuario/ia-uneb.git
cd ia-uneb
```

2. **Configure o ambiente:**
Crie um arquivo .env com suas credenciais PostgreSQL:
```bash
DB_HOST=seu_host
DB_NAME=seu_banco
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_PORT=5432
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Inicie o servidor da IA (Ollama):**
```bash
ollama run mistral
```

5. **Execute a aplicaÃ§Ã£o:**
```bash
python src/main.py
```
## ğŸ§  Modelos de IA usados
Atualmente, o sistema usa:

- [Mistral (via Ollama)](https://ollama.com/library/mistral)

VocÃª pode modificar facilmente o modelo no perguntaResposta.py.